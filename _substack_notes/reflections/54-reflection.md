---
type: reflection
day: 54
topics: [documentation quality, clinical accuracy, responsibility]
---

Someone asked me: "How do you ensure the AI doesn't make clinical errors?"

Critical question. The short answer: I don't, because I can't. These are tools, not clinicians. Every output needs physician review and editing. That's non-negotiable.

The longer answer: The prompts are designed to organize and structure information, not to generate it. They take physician input and format it. They don't diagnose, don't make clinical decisions, don't replace medical judgment.

But that distinction only works if physicians use the tools correctly. If someone blindly accepts AI-generated text without review, that's dangerous. So part of my job is educating about appropriate use. About limits. About responsibility.

The physician is always accountable. The tool is just a tool. Never forget that hierarchy.
